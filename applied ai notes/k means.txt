
K-Means : Lloyd's algorithm
1) initializations
	randomly pick k points from D and call them centroids.
2) Assignment 
	for each points in x i select the nearest centroid from set of centroids. for this you will compute distance between given point and all centroids and select lowest distance centroid as centroid for that point.
	add that point to set of points for given centroid.
3) Recompute the centroid 
4) repeate 2 and 3 until convergence.
5) when the distance between old and new centroid is very small we stop.

Initialization sensitivity = final result depends on initial random point selection.
how to handle initializations sensitivity : 
	run k means with different initial random point selction and select based on smaller intra cluster and larger inter cluster distance.
	K-Means++ = replaces random initializations with smart initializations schemes.initializations works as follows
		1) pick the first centroid randomly from dataset D.
		2) for each point in dataset d create a distribution as square of distance between that point and nearest centroid.
		3) but here we have only one centroid 

Limitations of k means : k means didn't work well in following cases 
	1) different sizes
	2) different densities
	3) non-globular(convex) shapes
	4) data have outliers
	
Solutions
1) take more k value.

K-medoids = instead to taking centroids in k means if we take points x i as means then it is called k medoids.

Partitioning around medoids(PAM) = here difference is third stage in k-means which is update.
	1) swap each medoid with non medoid points.
	2) if loss decreases keep tha swap else undo the swap. and try some another swap.
	3) here loss is inter cluster distance.
	4) once swap is successful we repeat second step i.e. assignment in k-means.

ways to Determine right k = 	
1) from domain knowledge (e.g. amazon fine food reviews here it is 2 ).
2) elbow method or knee method 

	