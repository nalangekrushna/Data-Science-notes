Docker provides the ability to package and run an application in a loosely isolated environment called a container. 

Docker provides tooling and a platform to manage the lifecycle of your containers:
	Develop your application and its supporting components using containers.
	The container becomes the unit for distributing and testing your application.
	When youâ€™re ready, deploy your application into your production environment, as a container or an orchestrated service.
	
Docker uses a client-server architecture. The Docker client talks to the Docker daemon, which does the heavy lifting of building, running, and distributing your Docker containers. The Docker client and daemon can run on the same system, or you can connect a Docker client to a remote Docker daemon. The Docker client and daemon communicate using a REST API, over UNIX sockets or a network interface.

All best practices are taken from pythonspeed.com and docker official guide.
docker best practices
	use python:3.7.3-stretch instead of python:3
	use requirements.txt instead of RUN pip install package_name.
	use COPY after pip install as you will able to get benefit of docker layer caching which will build fast.
	by default docker runs as root user, create another non-root user instead of using root.
	caching can lead to insecure images.
		https://pythonspeed.com/articles/official-docker-best-practices/   #1
	don't use alpine linux for python as it uses different implementation of gcc.
	
	
buster = current stable release
stretch = prev stable release
slim = minimal package needed to run
	
some good deployment articles
https://hynek.me/articles/