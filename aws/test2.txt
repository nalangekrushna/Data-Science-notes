test2

configure an SSL listener to their Classic Load Balancer and EC2 instances ?  
	-> Before you start using Elastic Load Balancing, you must configure one or more listeners for your Classic Load Balancer. A listener is a process that checks for connection requests. It is configured with a protocol and a port for front-end (client to load balancer) connections, and a protocol and a port for back-end (load balancer to back-end instance) connections.

	The HTTPS protocol uses the SSL protocol to establish secure connections over the HTTP layer. You can also use the SSL protocol to establish secure connections over the TCP layer. If the front-end connection uses TCP or SSL, then your back-end connections can use either TCP or SSL. If the front-end connection uses HTTP or HTTPS, then your back-end connections can use either HTTP or HTTPS.

	When you use TCP (layer 4) for both front-end and back-end connections, your load balancer forwards the request to the back-end instances without modifying the headers. After your load balancer receives the request, it attempts to open a TCP connection to the back-end instance on the port specified in the listener configuration.

	When you use HTTP (layer 7) for both front-end and back-end connections, your load balancer parses the headers in the request and terminates the connection before sending the request to the back-end instances. For every registered and healthy instance behind an HTTP/HTTPS load balancer, Elastic Load Balancing opens and maintains one or more TCP connections. These connections ensure that there is always an established connection ready to receive HTTP/HTTPS requests.

	Hence, the following are true statements about ELB listener configuration:
		-If the front-end connection uses TCP or SSL, then your back-end connections can use either TCP or SSL.
		-If the front-end connection uses HTTP or HTTPS, then your back-end connections can use either HTTP or HTTPS.
		-When you use HTTP (layer 7) for both front-end and back-end connections, your load balancer parses the headers in the request and terminates the connection before sending the request to the back-end instances.
		
connect three vpc with each other ?
	-> You may want to use a full mesh configuration when you have separate VPCs that need to share resources with each other without restrictions. following things should be taken care of 
	1. ensure vpcs don't have matching or overlapping ipv4 cidr blocks.
	2. setup vpc peering in full mesh config.
	3. update all route tables in each vpc with respective peering config.
	
For an EC2 instance to be able to communicate to the Internet over IPv6, the following configuration should be done in the VPC:
	-Associate a /56 IPv6 CIDR block with the VPC. The size of the IPv6 CIDR block is fixed (/56) and the range of IPv6 addresses is automatically allocated from Amazon's pool of IPv6 addresses (you cannot select the range yourself).
	-Create a subnet with a /64 IPv6 CIDR block in your VPC. The size of the IPv6 CIDR block is fixed (/64).
	-Create a custom route table, and associates it with your subnet, so that traffic can flow between the subnet and the Internet gateway.  

scenario connect on premise chicago network with two aws vpc one located in US East and other located in US West ?
	-> Set up an AWS Direct Connect connection to the on-premises data center. Launch a new AWS Direct Connect Gateway with a virtual private gateway and connect the VPCs from US East and US West regions. Integrate the Direct Connect connection to the Direct Connect Gateway.
	
	on premise -> customer gateway -> aws direct connect connection -> private virtual interface -> direct connect gateway -> virtual private gateway (in vpc's)
	
If you notice a significant increase in the number of HTTP 503-slow down responses received for Amazon S3 PUT or DELETE object requests to a bucket that has versioning enabled, you might have one or more objects in the bucket for which there are millions of versions. When you have objects with millions of versions, Amazon S3 automatically throttles requests to the bucket to protect the customer from an excessive amount of request traffic, which could potentially impede other requests made to the same bucket.

To allow administrators to easily manage tags on provisioned products, AWS Service Catalog provides a TagOption library. A TagOption is a key-value pair managed in AWS Service Catalog.

Cross-zone load balancing reduces the need to maintain equivalent numbers of instances in each enabled Availability Zone. cross zone load balancing distributes load according total no of instances so all instances are evenly loaded irrespective of their AZ. In case cross zone load balancing disabled load balancer evenly distribute load according no of AZ. So all zones are evenly loaded.

Enabling billing alerts in Account Preferences of the AWS Console. Before you can create an alarm for your estimated charges, you must enable billing alerts on your Accounts Preferences page first, so that you can monitor your estimated AWS charges and create an alarm using billing metric data. After you enable billing alerts, you cannot disable data collection, but you can delete any billing alarms that you created.

The following are a few reasons why your EC2 instance goes from the pending state to the terminated state immediately after restarting it:
	-You've reached your EBS volume limit.
	-An EBS snapshot is corrupt.
	-The root EBS volume is encrypted and you do not have permissions to access the KMS key for decryption.
	-The instance store-backed AMI that you used to launch the instance is missing a required part (an image.part.xx file).
	
To fix the policy, you simply have to specify two items under the Resource section: one for the s3:GetObject action and another one for the s3:ListBucket action. Take note that the s3:GetObject action is using a wildcard ( /* ) which refers to all of the objects in the bucket. The mapping is as follows:
s3:GetObject = arn:aws:s3:::tutorialsdojo/*
s3:ListBucket = arn:aws:s3:::tutorialsdojo

to launch an RDS-MySQL Instance that will host a heavily used relational database. Manual snapshots of the database are done on schedule in disaster recovery activities. there should no outages when a snapshot is being created for the database.   
	-> The best answer is to re-design the RDS instance to use Multi-AZ deployments configuration.

	This is stated in the AWS documentation: Amazon RDS creates a storage volume snapshot of your DB instance, backing up the entire DB instance and not just individual databases. Creating this DB snapshot on a Single-AZ DB instance results in a brief I/O suspension that can last from a few seconds to a few minutes, depending on the size and class of your DB instance. Multi-AZ DB instances are not affected by this I/O suspension since the backup is taken on the standby.
	
	Creating a Read Replica of the primary RDS database and take the snapshot from the replica is incorrect. Although this can help mitigate the I/O suspension, a heavily used database can have many changes in a short amount of time and snapshots taken from read replicas may not include all the transactions present on the master at that time because of possible replica lag.