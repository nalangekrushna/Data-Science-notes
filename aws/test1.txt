aws tests from udemy course  
test 1

kinesis = aws kinesis is real time fully managed and scalable data streaming service which enables real time data analytics. It can be used with video, audio, logs, website clickstreams as well as IoT telemetry data. Kinesis video stream uses TLS encryption for data at transport and aws KMS to encrypt data at rest.

kinesis data firehose = used to store data in desired aws storages such as s3 bucket or aws redshift.

When you use Amazon Redshift Enhanced VPC Routing, Amazon Redshift forces all COPY and UNLOAD traffic between your cluster and your data repositories through your Amazon VPC. By using Enhanced VPC Routing, you can use standard VPC features, such as VPC security groups, network access control lists (ACLs), VPC endpoints, VPC endpoint policies, internet gateways, and Domain Name System (DNS) servers. Hence, enabling Enhanced VPC routing on your Amazon Redshift cluster is the correct answer. If Enhanced VPC Routing is not enabled, Amazon Redshift routes traffic through the Internet, including traffic to other services within the AWS network.

Your instances are failing to launch for some reason. An error message is saying that "EC2 instance <instance ID> is in VPC. Updating load balancer configuration failed".  ?
-> This error is produced when the ELB and the Auto Scaling group are not created in the same network. Make sure that both are in VPC or in EC2-Classic. 

Auto Scaling = Dynamic scaling responds to changing demand and predictive scaling automatically schedules the right number of EC2 instances based on predicted demand. Dynamic scaling and predictive scaling can be used together to scale faster. Auto Scaling uses both this features for scaling. scaling in means decreasing size whereas scaling out means increasing size. You can specify min, max and desired no of instances. your ec2 instances are orgainzed in groups. groups are treated as logical units for scaling. your group uses launch configuration to launch ec2 instances. we can use lifecycle hooks to to perform custom operations when changing instance state.
If you suspend the Terminate process, your Auto Scaling group can grow up to ten percent larger than its maximum size, because this is allowed temporarily during rebalancing activities. If the scaling process cannot terminate instances, your Auto Scaling group could remain above its maximum size until you resume the Terminate process.
auto scaling groups cannot scale out to other aws regions. Launching an Auto Scaling Group with subnets across 2 Availability Zones and setting the minimum and maximum capacity to 1 is incorrect as setting the maximum capacity to 1 means that the Auto Scaling group will not be able to scale out as required.

scaling policy type = 
	Target tracking scaling = scales in or out to keep target metrics value near to user provided value
	step scaling = adjust in proportional of size of alarm breach. step scaling is better and generally recommended than simple scaling.
	simple scaling = scale in or out upon breach of threshold.
	scheduled scaling = scale in or out at specific timing.
A cooldown period helps you prevent your Auto Scaling group from launching or terminating additional instances before the effects of previous activities are visible. auto scaling marks instance unhealthy if it is in other state than running.

auto scaling standby state = auto scaling didn't do health check on standby instances. standby state is used for performing updates/changes/troubleshooting or replacement instaces being launched.

data analytics application = high sequential read-write access = storage optimized instances.

ec2 instance types = https://aws.amazon.com/ec2/faqs/#Instance_types

vpc = you can connect vpc to on-premise network by using IPsec AWS managed VPN connection. A vpn connection consist of virtual private gateway and customer gateway. you can use transit gateway instead of virtual private gateway to connect vpn to multiple vpcs and resources.

S3 advanced services =
Amazon S3 inventory is one of the tools Amazon S3 provides to help manage your storage. You can use it to audit and report on the replication and encryption status of your objects. You can also specify that the inventory list file is encrypted. You can query Amazon S3 inventory using standard SQL by using Amazon Athena, Amazon Redshift Spectrum
S3 Analytics is primarily used to analyze storage access patterns to help you decide when to transition the right data to the right storage class. 
S3 Select is used to retrieve specific data from the contents of an object using simple SQL expressions without having to retrieve the entire object.

aws lambda = If you're using the AWS Lambda compute platform, you must choose one of the following deployment configuration types to specify how traffic is shifted from the original AWS Lambda function version to the new AWS Lambda function version:
	Canary: Traffic is shifted in two increments. You can choose from predefined canary options that specify the percentage of traffic shifted to your updated Lambda function version in the first increment and the interval, in minutes, before the remaining traffic is shifted in the second increment.
	Linear: Traffic is shifted in equal increments with an equal number of minutes between each increment. You can choose from predefined linear options that specify the percentage of traffic shifted in each increment and the number of minutes between each increment.
	All-at-once: All traffic is shifted from the original Lambda function to the updated Lambda function version at once.
	
VPC Flow Logs = enables you to capture information about the IP traffic going to and from network interfaces in your VPC. Flow log data can be published to Amazon CloudWatch Logs and Amazon S3. After you've created a flow log, you can retrieve and view its data in the chosen destination.
Flow logs can help you with a number of tasks; for example, to troubleshoot why specific traffic is not reaching an instance, which in turn helps you diagnose overly restrictive security group rules. You can also use flow logs as a security tool to monitor the traffic that is reaching your instance.

Enabling Auto Scaling for the DynamoDB table is the best answer. DynamoDB Auto Scaling uses the AWS Application Auto Scaling service to dynamically adjust provisioned throughput capacity on your behalf, in response to actual traffic patterns. This enables a table or a global secondary index to increase its provisioned read and write capacity to handle sudden increases in traffic, without throttling. When the workload decreases, Application Auto Scaling decreases the throughput so that you donâ€™t pay for unused provisioned capacity.

RAID = raid is accomplished at software level. For greater I/O performance than you can achieve with a single volume, RAID 0 can stripe multiple volumes together; for on-instance redundancy, RAID 1 can mirror two volumes together which can also offer fault tolerance. RAID 5 and RAID 6 are not recommended for Amazon EBS because the parity write operations of these RAID modes consume some of the IOPS available to your volumes.