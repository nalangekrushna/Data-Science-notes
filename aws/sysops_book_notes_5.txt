Amazon Aurora = fully managed, MySQL-compatible, relational database engine. An Amazon Aurora cluster volume is a virtual database storage volume that spans multiple Availability Zones, with each Availability Zone containing a copy of the cluster data. Two types of instances make up an Aurora DB cluster
	Primary Instance = A primary instance supports read-write workloads and performs all of the data modifi cations to the cluster volume. Each Amazon Aurora DB cluster has one primary instance.
	Aurora Replica = An Aurora Replica supports only read operations. Each DB cluster can have up to 15 Aurora Replicas in addition to the primary instance
Aurora cluster volume/table can grow to a maximum size of 64 TB.	

Performance metrics by aws
IOPS = The number of I/O operations completed per second.
Latency = The elapsed time between the submission of an I/O request and its completion.
Throughput = The number of bytes per second transferred to or from disk.
Queue depth = The number of I/O requests in the queue waiting to be serviced.

all above metrics given as average in given time interval

Amazon RDS Multi-AZ deployments do not fail over automatically in response to database operations such as long running queries, deadlocks, or database corruption errors.

DynamoDB = NoSQL database supporting both document and key/value store models.
Items = Each table contains multiple items. An item is a group of attributes uniquely identifi able among all of the other items.Items in Amazon DynamoDB are similar in many ways to rows, records, or tuples in relational database systems.
Attributes = Each item is composed of one or more attributes. An attribute is a fundamental data element something that does not need to be broken down any further. Attributes in Amazon DynamoDB are similar to fi elds or columns in relational database systems.

Streams = ordered fl ow of information about changes to items. A stream record contains information about a data modifi cation to a single item in a DynamoDB table.

Data Types = 
	Scalar = Number, String, Binary, Boolean, and Null
		Binary = Binary type attributes can store any binary data, such as compressed text, encrypted data, or images. The length of a binary attribute must be greater than zero and is constrained by the maximum Amazon DynamoDB item size limit of 400 KB.
	Document = There are two document types, list and map, that can be nested within each other to represent complex data structures up to 32 levels deep. There is no limit on the number of values in a list or a map as long as the item containing the values fits within the Amazon DynamoDB item size limit of 400 KB. An attribute value cannot be an empty string or an empty set; however, empty lists and maps are allowed.
		List = A list type attribute can store an ordered collection of values. Lists are enclosed in square brackets: [ ... ]. A list is similar to a JSON array. There are no restrictions on the data types that can be stored in a list element, and the elements in a list element can be different types.
		Map = A map type attribute can store an unordered collection of name/value pairs. Maps are enclosed in curly braces: { ... }. A map is similar to a JSON object. There are no restrictions on the data types that can be stored in a map element, and elements in a map do not have to be the same type.
		Set = number, string, or binary, All of the elements within a set must be of the same type. There is no limit on the number of values in a set, as long as the item containing the values fi ts within the Amazon DynamoDB 400 KB item size limit. Each value within a set must be unique. The order of the values within a set are not preserved. Amazon DynamoDB does not support empty sets.

Amazon DynamoDB supports eventually consistent and strongly consistent reads. Unless specified otherwise, DynamoDB uses eventually consistent reads as the default. When a strongly consistent read is requested, Amazon DynamoDB returns a response with the most up-to-date data that refl ects the updates from all prior write operations that were successful.

Redshift = fully managed data warehousing solution. It automates infrastructure provisioning and administrative tasks, such as backups, replication, and patching.

Redshift Spectrum = runs SQL queries directly against exabytes of unstructured data in Amazon S3.

Leader Nodes = A leader node receives queries from client applications, parses the queries, and develops execution plans. These plans are an ordered set of steps to process these queries. The leader node coordinates the parallel execution of these plans with the compute nodes, aggregates the intermediate results from these nodes, and returns the results to the client applications.

Compute Nodes = Compute nodes execute the steps specified in the execution plans and transmit data among themselves to serve these queries. The intermediate results are sent back to the leader node for aggregation before being sent to the client applications.

ElastiCache = a distributed in-memory cache environment in the cloud.

Simple Queue Service(SQS) = access to message queues that store messages waiting to be processed. Amazon SQS queues retain messages for a set period of time. The default setting is four days; however, you can configure a queue to retain messages for up to 14 days.

Dead Letter Queue (DLQ) is an Amazon SQS queue that you configure to receive messages from other Amazon SQS queues, referred to as “source queues.” Typically, you set up a DLQ to receive messages after a maximum number of processing attempts has been reached.

Simple Notification Service (SNS) = manages the delivery or sending of messages to subscribing endpoints or clients. In Amazon SNS, there are two types of clients—publishers and subscribers, which are also referred to as producers and consumers. Publishers communicate asynchronously with subscribers by producing and sending a message to a topic, which is a logical access point and communication channel. Subscribers (for example web servers, email addresses, Amazon SQS queues, and AWS Lambda functions) consume or receive the message or notification over one of the supported protocols (such as Amazon SQS, HTTP/S, email, Short Message Service [SMS], or AWS Lambda) when they are subscribed to the topic.

Recovery time objective (RTO) = This represents the time it takes after a disruption to restore a business process to its service level.

Recovery point objective (RPO) = This is the acceptable amount of data loss measured in time. For example, if a disaster occurs at 12:00 PM (noon) and the RPO is one hour, the system should recover all data that was in the system before 11:00 AM.

Warm-Standby Method = a scaled-down version of a fully-functional environment is always running in the cloud.

pilot light method = a minimal version of an environment is always running in AWS.

Multi-Site Solution Method = A multi-site solution runs in AWS, as well as on your existing on-site infrastructure, in an active-active configuration.